---
title: "So Bolt Gave Me a Driving Score. Now I Have Questions."
date: 2026-01-03
draft: false
tags: ["AI", "EU AI Act", "regulation"]
---

A few months ago I rented a Bolt van, and at the end of my trip I got a score: 97/100 for my driving style. Cool, I guess? But here's the thing — I've been digging into the EU AI Act for my research, and this little number got me curious. Where does a system like this actually fall under the new rules?

I don't have any insider info on how Bolt's scoring works, so think of this as me working through the question out loud rather than any kind of legal verdict.

<img src="/images/photo_2026-01-03%2013.41.23.jpeg" alt="Bolt ride summary showing a 97/100 driving score" style="max-width: 400px;">

## Wait, What's the EU AI Act Again?

With "AI" slapped on everything from toasters to toothbrushes, you might have missed this one. Basically, it's a set of EU rules that sorts AI systems into risk categories. The one that matters most for everyday stuff is "high-risk" — systems that affect things like your access to services, your credit, or how companies treat you based on profiling.

If your system lands in that bucket, you've got obligations. Transparency. Human oversight. And starting August 2026, users can ask for an explanation of how the AI reached its decision about them.

## First Thing I Wondered: Is This Even AI?

Maybe not! If Bolt just uses simple rules — like "lose 2 points if you speed in a 50 zone for more than 5 minutes" — then it's not AI under the Act. Just regular old code doing regular old things.

But let's say there's an actual model behind the score, trained on driving data. That's when it gets interesting.

## The Real Question: What Happens With My Score?

This is where it matters. If the score is just for fun — a little "hey, you braked hard twice" feedback — probably not high-risk. I see it, I shrug, life goes on.

But what if a low score means I pay more next time? Or I can't rent certain vehicles? Now we're talking about something that actually affects me as a customer. That's when the high-risk rules kick in.

## Why Should I Care?

Here's the part I find genuinely useful. If a system is high-risk, I get to ask questions. How did you calculate this? What data went into it? Why did I get this result?

If you've ever sent a GDPR request asking a company "what data do you have on me," it's a similar idea. Except now it's not just about the data — it's about what the AI did with it.

## So What Now?

The explanation rights come into force in August 2026. That's not far off. For companies running these kinds of scoring systems, the clock is ticking. For the rest of us, it means we'll soon have a way to peek behind the curtain when an algorithm decides something about us.

As for my 97/100 — I'm still not sure what I did wrong.

---

## Sources

- [Regulation (EU) 2024/1689 - Artificial Intelligence Act](https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng) (EUR-Lex)
- [Bolt Drive rental cars in Estonia to start monitoring drivers' habits](https://news.err.ee/1609771413/bolt-drive-rental-cars-in-estonia-to-start-monitoring-drivers-habits) (ERR News)
